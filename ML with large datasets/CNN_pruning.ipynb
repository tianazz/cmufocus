{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "a3hgfPLAL7RD",
        "BO56HtlvxN3S",
        "ywX9mTM57Vqo"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-eC-sb34T9w"
      },
      "source": [
        "## Accelerate Inference: Neural Network Pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L47XBZWm4T9x",
        "outputId": "4cc84474-0dd1-4d4d-b5cb-e175462907fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models, regularizers\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "print(tf.version.VERSION)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDMHqKQw8DDS",
        "outputId": "10f24a9e-584d-4578-bd35-1a53d44a5715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1FQTVeAuNiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75943476-9091-40a1-e7f8-e9537618fd1e"
      },
      "source": [
        "# untar\n",
        "!tar -xvzf \"/content/drive/My Drive/10605-ProjA/dataset.tar.gz\"\n",
        "#!tar -xvzf \"/content/drive/My Drive/Dataset.tar.gz\"   #ztt path \n",
        "\n",
        "# load train\n",
        "train_images = pickle.load(open('train_images.pkl', 'rb'))\n",
        "train_labels = pickle.load(open('train_labels.pkl', 'rb'))\n",
        "# load val\n",
        "val_images = pickle.load(open('val_images.pkl', 'rb'))\n",
        "val_labels = pickle.load(open('val_labels.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_images.pkl\n",
            "train_labels.pkl\n",
            "val_images.pkl\n",
            "val_labels.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE9JuZDG4T94"
      },
      "source": [
        "# Define the neural network architecture (don't change this)\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5), input_shape=(25,25,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(1e-5)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTzcSoYl4T97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "036a58d9-c1bf-4d1a-ac39-06fece4840fc"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 25, 25, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 25, 25, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 23, 23, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 23, 23, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 11, 11, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 11, 11, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 11, 11, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 9, 9, 64)          36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 9, 9, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               524800    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 592,933\n",
            "Trainable params: 592,933\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9Nk_MAPqZPt"
      },
      "source": [
        "# you can use the default hyper-parameters for training, \n",
        "# and val accuracy ~59% after 25 epochs and > 63% after 50 epochs\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, batch_size=32, verbose = 0, epochs=180, \n",
        "                    validation_data=(val_images, val_labels)) # train for 180 epochs, with batch size 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOhpP7M24T9_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0055568c-049f-4331-d08a-223b060081dd"
      },
      "source": [
        "# evaluate baseline model\n",
        "loss, val_accuracy = model.evaluate(val_images, val_labels, batch_size=128)\n",
        "\n",
        "print(\"Baseline model, accuracy: {:5.2f}%\".format(100 * val_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 10ms/step - loss: 0.8683 - accuracy: 0.7453\n",
            "Baseline model, accuracy: 74.53%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create dir to save model & accuracy on google drive\n",
        "!mkdir -p \"/content/drive/My Drive/10605-ProjA/saved_model/\""
      ],
      "metadata": {
        "id": "lIIw2S30IOxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "model.save('/content/drive/My Drive/10605-ProjA/saved_model/baseline_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUSdFM0zAYmU",
        "outputId": "bc89cc99-029f-4970-f30a-ac6a859b960d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save baseline_model val_accuracy\n",
        "acc_base_model = {\"acc\":val_accuracy}\n",
        "import numpy as np\n",
        "np.save('/content/drive/My Drive/10605-ProjA/saved_model/baseline_model/acc_base_model_score.npy', acc_base_model) "
      ],
      "metadata": {
        "id": "PJZ_cdlWHKqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.load('/content/drive/My Drive/10605-ProjA/saved_model/baseline_model/acc_base_model_score.npy',allow_pickle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYhFpwKnH6Uf",
        "outputId": "8f717a64-78d6-4699-a4a2-89d89ffe4236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array({'acc': 0.7453465461730957}, dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reload model\n",
        "re_model = tf.keras.models.load_model('/content/drive/My Drive/10605-ProjA/saved_model/baseline_model')\n",
        "\n",
        "# Check its architecture\n",
        "re_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUDea6JgJCkb",
        "outputId": "9b25cdad-6d0b-49ce-d868-d6538b766afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 25, 25, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 25, 25, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 23, 23, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 23, 23, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 11, 11, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 11, 11, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 11, 11, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 9, 9, 64)          36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 9, 9, 64)          0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               524800    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 5)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 592,933\n",
            "Trainable params: 592,933\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#recompile model\n",
        "re_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# verify the saved model\n",
        "loss, val_accuracy = re_model.evaluate(val_images, val_labels, batch_size=128)\n",
        "\n",
        "print(\"Baseline model, accuracy: {:5.2f}%\".format(100 * val_accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEIk5BrgJYUD",
        "outputId": "3282bda0-e0af-4c73-cd0b-b8e89e6b75ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 1/20 [>.............................] - ETA: 4s - loss: 1.4206 - accuracy: 0.6172"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 5ms/step - loss: 0.8683 - accuracy: 0.7453\n",
            "Baseline model, accuracy: 74.53%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Method 1: Magnitude-based pruning**"
      ],
      "metadata": {
        "id": "1cVkWAG5_ir0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reload model\n",
        "model_1 = tf.keras.models.load_model('/content/drive/My Drive/10605-ProjA/saved_model/baseline_model')\n",
        "\n",
        "#recompile model\n",
        "model_1.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_1.fit(train_images, train_labels, batch_size=32, verbose = 0, epochs=1, \n",
        "                    validation_data=(val_images, val_labels)) # train for 1 epoch, with batch size 32\n",
        "\n",
        "# verify the saved model\n",
        "loss_1, val_accuracy_1 = model_1.evaluate(val_images, val_labels, batch_size=128)\n",
        "\n",
        "print(val_accuracy_1)\n"
      ],
      "metadata": {
        "id": "fa4btjvW_iHH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff9a7448-5d09-46fc-b715-4a0d5add1c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 0s 7ms/step - loss: 0.8592 - accuracy: 0.7485\n",
            "0.7485148310661316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pruning function\n",
        "from copy import deepcopy\n",
        "\n",
        "def prune_weights(weight_list,pruning_rate):\n",
        "    for i in range(weight_list.shape[-1]):\n",
        "        copy_weight= deepcopy(weight_list[...,i])\n",
        "        std=np.std(copy_weight)\n",
        "        threshold= std*pruning_rate\n",
        "        weight_list[...,i][np.abs(weight_list[...,i]) < threshold]=0\n",
        "    return weight_list\n",
        "\n"
      ],
      "metadata": {
        "id": "zQhQDIDX9HoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_nonzeros(model):\n",
        "    nonzero = total = 0\n",
        "    for i in range(len(model.variables)):\n",
        "      if \"kernel\" in model.variables[i].name:\n",
        "        name=model.variables[i].name\n",
        "        tensor=model.variables[i].numpy()\n",
        "        nz_count=np.count_nonzero(tensor)\n",
        "        total_params = np.prod(tensor.shape)\n",
        "        nonzero += nz_count\n",
        "        total += total_params\n",
        "        print(f'{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | total_pruned = {total_params - nz_count :7} | shape = {tensor.shape}')\n",
        "    print(f'Active: {nonzero}, Pruned : {total - nonzero}, Total: {total}, Compression rate : {total/nonzero:10.2f}x  ({100 * (total-nonzero) / total:6.2f}% pruned)')\n",
        " "
      ],
      "metadata": {
        "id": "wqbBiaknnnsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weight pruning\n",
        "pretrained_model= model_1  \n",
        "quality_parameter = 1.0      #sensitivity factor to calculate threshold\n",
        "\n",
        "#Pruning\n",
        "for layerid in range(len(pretrained_model.layers)):\n",
        "  layer=pretrained_model.layers[layerid]\n",
        "  weight=layer.get_weights()\n",
        "  if len(weight) > 0:\n",
        "          temp_weight=deepcopy(weight)\n",
        "          updated_weights = prune_weights(temp_weight[0],quality_parameter) #function call to prune weight based on threshold\n",
        "          temp_weight[0]= updated_weights\n",
        "          layer.set_weights(temp_weight)   #set layers weights with pruned weight\n",
        "\n",
        "#retrain the model\n",
        "pretrained_model.fit(train_images, train_labels, batch_size=32, verbose = 0, epochs=50, \n",
        "                  validation_data=(val_images, val_labels)) # train for 50 epochs, with batch size 32\n",
        "\n",
        "pruned_loss,pruned_accuracy = pretrained_model.evaluate(val_images, val_labels, batch_size=128, verbose=0) \n",
        "\n",
        "print('Accuracy before Pruning:',val_accuracy_1)\n",
        "print('Accuracy after Pruning:',pruned_accuracy)\n",
        "\n",
        "print_nonzeros(pretrained_model)   #function to measure pruned weights and compression rate"
      ],
      "metadata": {
        "id": "CXNFsJF3nn0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b363557d-955e-4e14-8708-f48f6db4891f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy before Pruning: 0.7485148310661316\n",
            "Accuracy after Pruning: 0.7556435465812683\n",
            "conv2d/kernel:0      | nonzeros =     864 /     864 (100.00%) | total_pruned =       0 | shape = (3, 3, 3, 32)\n",
            "conv2d_1/kernel:0    | nonzeros =    9216 /    9216 (100.00%) | total_pruned =       0 | shape = (3, 3, 32, 32)\n",
            "conv2d_2/kernel:0    | nonzeros =   18432 /   18432 (100.00%) | total_pruned =       0 | shape = (3, 3, 32, 64)\n",
            "conv2d_3/kernel:0    | nonzeros =   36864 /   36864 (100.00%) | total_pruned =       0 | shape = (3, 3, 64, 64)\n",
            "dense/kernel:0       | nonzeros =  522037 /  524288 ( 99.57%) | total_pruned =    2251 | shape = (1024, 512)\n",
            "dense_1/kernel:0     | nonzeros =    2555 /    2560 ( 99.80%) | total_pruned =       5 | shape = (512, 5)\n",
            "Active: 589968, Pruned : 2256, Total: 592224, Compression rate :       1.00x  (  0.38% pruned)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Save weights**"
      ],
      "metadata": {
        "id": "a3hgfPLAL7RD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMSKQW4k4T-G",
        "outputId": "df01e607-d90f-46a4-aced-8bf77aa49740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "# you need to save the model's weights, naming it 'my_model_weights.h5'\n",
        "pretrained_model.save_weights(\"my_model_weights_1.h5\")\n",
        "\n",
        "# running this cell will immediately download a file called 'my_model_weights.h5'\n",
        "from google.colab import files\n",
        "files.download(\"my_model_weights_1.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7b848141-8f03-429c-8bf5-07ede8fb3564\", \"my_model_weights_1.h5\", 2407560)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Method 2: SNIP（Single-shot Network Pruning）**"
      ],
      "metadata": {
        "id": "hixvaP3K0Jqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reload model\n",
        "model_2 = tf.keras.models.load_model('/content/drive/My Drive/10605-ProjA/saved_model/baseline_model')\n",
        "\n",
        "#recompile model\n",
        "model_2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ukjMwPvZ0NOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class Newcallback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, masks):\n",
        "    super(Newcallback, self).__init__()\n",
        "    self.masks = masks\n",
        "\n",
        "  def _prune(self, model) :\n",
        "    for var, mask in list(zip(self.model.trainable_variables, self.masks)):\n",
        "      var.assign(tf.math.multiply(var.read_value(), mask))\n",
        "\n",
        "  def on_train_batch_begin(self, batch, logs=None):\n",
        "    self._prune(self.model)\n",
        "\n",
        "  def on_train_batch_end(self, batch, logs=None):\n",
        "    self._prune(self.model)\n",
        "\n",
        "\n",
        "def makeCallback(model, sparsity, x, y) :\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred  = model(x)\n",
        "    loss = model.compiled_loss(y,y_pred)    \n",
        "\n",
        "  grads = tape.gradient(loss,model.trainable_variables)\n",
        "  saliences = [tf.abs(grad*weight) for weight, grad in zip(model.trainable_variables, grads)]\n",
        "  saliences_flat = tf.concat([tf.reshape(x,-1) for x in saliences], 0)\n",
        "  \n",
        "  k = tf.dtypes.cast(\n",
        "          tf.math.round(\n",
        "              tf.dtypes.cast(tf.size(saliences_flat), tf.float32) *\n",
        "              (1 - sparsity)), tf.int32)\n",
        "  values,_ = tf.math.top_k(saliences_flat, k=tf.size(saliences_flat))\n",
        "  current_threshold = tf.gather(values, k-1)\n",
        "  masks = [tf.cast(tf.greater_equal(s,current_threshold),dtype=s.dtype) for s in saliences]\n",
        "\n",
        "  return Newcallback(masks)"
      ],
      "metadata": {
        "id": "qXL1ajfxyf6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_sparsity(model):\n",
        "    total_weights = np.concatenate([x.numpy().flatten() for x in model.trainable_variables])\n",
        "    sparsity = 1 - np.count_nonzero(total_weights)/total_weights.size\n",
        "    return sparsity"
      ],
      "metadata": {
        "id": "hPTE1rmIy8KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    return lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),cooldown=0,patience=5,min_lr=0.5e-6)"
      ],
      "metadata": {
        "id": "36DTlbh33V_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparsity = 0.4\n",
        "\n",
        "pc = makeCallback(\n",
        "    model_2,\n",
        "    sparsity,\n",
        "    tf.convert_to_tensor(train_images[1:10]),\n",
        "    tf.convert_to_tensor(train_labels[1:10])\n",
        "    )\n",
        "\n",
        "callbacks = [pc,lr_reducer,lr_scheduler]"
      ],
      "metadata": {
        "id": "I8wiroOv4dU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.fit(train_images, train_labels, batch_size=32, \n",
        "            verbose=0, epochs=20, \n",
        "            validation_data=(val_images, val_labels),\n",
        "            callbacks=callbacks\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8y7AkpX4yNv",
        "outputId": "a2b2f48a-9185-4fa1-b384-a79f9b65fe14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd2e740f340>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sparsity after pruning:\")\n",
        "print(calc_sparsity(model_2))\n",
        "print(\"Loss and Accuracy after pruning:\")\n",
        "print(model_2.evaluate(val_images,val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgDTiAvh5z1d",
        "outputId": "b6d48027-d09a-47c5-974d-ad48da44ffa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity after pruning:\n",
            "0.47933240349246875\n",
            "Loss and Accuracy after pruning:\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.7645 - accuracy: 0.7636\n",
            "[0.7645334005355835, 0.7635643482208252]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Save weights**"
      ],
      "metadata": {
        "id": "BO56HtlvxN3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.save_weights(\"my_model_weights_2.h5\")"
      ],
      "metadata": {
        "id": "_H2U3sJSxSmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"my_model_weights_2.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QSW0Kziz0J_g",
        "outputId": "5ab293d8-59f4-4d69-bbeb-0f147296a1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_80f8e4ad-fc7c-4ad2-8d86-47f3e1676baa\", \"my_model_weights_2.h5\", 2407560)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Method 3: Neuron Pruning**"
      ],
      "metadata": {
        "id": "36KtVqPCyVEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#reload model\n",
        "model_3 = tf.keras.models.load_model('/content/drive/My Drive/10605-ProjA/saved_model/baseline_model')   # ztt path\n",
        "\n",
        "#recompile model\n",
        "model_3.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "s2QIFMPTybXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11luti6E2I-C",
        "outputId": "cd7fa031-12f2-4fa2-bde4-18a2838f8da7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.layers.convolutional.conv2d.Conv2D at 0x7ffb6016c510>,\n",
              " <keras.layers.core.activation.Activation at 0x7ffaf37de9d0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7ffaf37de190>,\n",
              " <keras.layers.core.activation.Activation at 0x7ffaf37dfe10>,\n",
              " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x7ffaf37e68d0>,\n",
              " <keras.layers.regularization.dropout.Dropout at 0x7ffaf37e53d0>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7ffaf37e59d0>,\n",
              " <keras.layers.core.activation.Activation at 0x7ffaf37e8b50>,\n",
              " <keras.layers.convolutional.conv2d.Conv2D at 0x7ffaf37ed550>,\n",
              " <keras.layers.core.activation.Activation at 0x7ffb0a386a50>,\n",
              " <keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x7ffb0a2eee10>,\n",
              " <keras.layers.regularization.dropout.Dropout at 0x7ffb0a2dfcd0>,\n",
              " <keras.layers.reshaping.flatten.Flatten at 0x7ffb0a2e4390>,\n",
              " <keras.layers.core.dense.Dense at 0x7ffb0a354710>,\n",
              " <keras.layers.core.activation.Activation at 0x7ffaf37edf50>,\n",
              " <keras.layers.regularization.dropout.Dropout at 0x7ffaf37ee6d0>,\n",
              " <keras.layers.core.dense.Dense at 0x7ffaf37f0090>,\n",
              " <keras.layers.core.activation.Activation at 0x7ffaf37f0a90>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_layers = len(model_3.layers)\n",
        "total_layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omf22qxV2OeU",
        "outputId": "d0f32782-0e73-4315-8de3-e7e93e1e2593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(model_3.get_weights())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yi8e7e-Z3diM",
        "outputId": "f79ccab9-8329-4dbb-b10e-8cb8f4637528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pruning function\n",
        "from numpy import linalg as LA\n",
        "def unit_prune(k_weights, b_weights, k_sparsity):\n",
        "    \"\"\"\n",
        "    Takes in matrices of kernel and bias weights (for a dense\n",
        "      layer) and returns the unit-pruned versions of each\n",
        "    Args:\n",
        "      k_weights: matrix of the \n",
        "      b_weights: matrix of the biases of a dense layer\n",
        "      k_sparsity: percentage of weights to set to 0\n",
        "    Returns:\n",
        "      kernel_weights: sparse matrix with same shape as the original\n",
        "        kernel weight matrix\n",
        "      bias_weights: sparse array with same shape as the original\n",
        "        bias array\n",
        "    \"\"\"\n",
        "\n",
        "    # Copy the kernel weights and get ranked indeces of the\n",
        "    # column-wise L2 Norms\n",
        "    kernel_weights = np.copy(k_weights)\n",
        "    \n",
        "    ind = np.argsort(LA.norm(kernel_weights, axis=0))\n",
        "    \n",
        "    # Number of indexes to set to 0\n",
        "    cutoff = int(len(ind)*k_sparsity)\n",
        "    # The indexes in the kernel weight matrix to set to 0\n",
        "    sparse_cutoff_inds = ind[0:cutoff]\n",
        "    \n",
        "    kernel_weights[:, sparse_cutoff_inds] = 0.\n",
        "        \n",
        "    # Copy the bias weights and get ranked indeces of the abs\n",
        "    bias_weights = np.copy(b_weights)\n",
        "    # The indexes in the 1D bias weight matrix to set to 0\n",
        "    # Equal to the indexes of the columns that were removed in this case\n",
        "    #sparse_cutoff_inds\n",
        "    bias_weights[sparse_cutoff_inds] = 0.\n",
        "    \n",
        "    return kernel_weights, bias_weights\n",
        "\n"
      ],
      "metadata": {
        "id": "qPTjf6iW4F3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sparsify_model(model, k_sparsity):\n",
        "    \"\"\"\n",
        "    Takes in a model made of dense layers and prunes the weights\n",
        "    Args:\n",
        "      model: Keras model\n",
        "      k_sparsity: target sparsity of the model\n",
        "    Returns:\n",
        "      sparse_model: sparsified copy of the previous model\n",
        "    \"\"\"\n",
        "    # Copying a temporary sparse model from our original\n",
        "    sparse_model = tf.keras.models.clone_model(model)\n",
        "    \n",
        "    # Getting a list of the names of each weights of each layer\n",
        "    names = [weight.name for layer in sparse_model.layers for weight in layer.weights]\n",
        "    # Getting the list of the weights for each of each layer\n",
        "    weights = sparse_model.get_weights()\n",
        "    \n",
        "    # Initializing list that will contain the new sparse weights\n",
        "    newWeightList = []\n",
        "\n",
        "    # Iterate over all but the final 1 layer\n",
        "    for i in range(0, len(weights)-2, 2):\n",
        "        kernel_weights, bias_weights = unit_prune(weights[i],weights[i+1],k_sparsity)\n",
        "        \n",
        "        # Append the new weight list with our sparsified kernel weights\n",
        "        newWeightList.append(kernel_weights)\n",
        "        \n",
        "        # Append the new weight list with our sparsified bias weights\n",
        "        newWeightList.append(bias_weights)\n",
        "    # Add the last layer weight     \n",
        "    for i in range(len(weights)-2, len(weights)):\n",
        "        unmodified_weight = np.copy(weights[i])\n",
        "        newWeightList.append(unmodified_weight)\n",
        "    \n",
        "    # Setting the weights of our model to the new ones\n",
        "    sparse_model.set_weights(newWeightList)\n",
        "    \n",
        "    # Re-compiling the Keras model\n",
        "    sparse_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "    \n",
        "    return sparse_model\n",
        " "
      ],
      "metadata": {
        "id": "OkkCU7Et5nlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_sparsities = [0.2]\n",
        "\n",
        "for k in k_sparsities:\n",
        "    sparse_model = sparsify_model(model_3, k_sparsity=k)\n",
        "    sparse_model.fit(train_images, train_labels, batch_size=32, verbose = 0, epochs=50, \n",
        "                    validation_data=(val_images, val_labels)) # retrain for 50 epochs, with batch size 32\n",
        "    print(\"sparsity\" + str(k))\n",
        "    print(\"Loss and Accuracy after pruning:\")\n",
        "    print(sparse_model.evaluate(val_images,val_labels))\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFf-AGajA4BQ",
        "outputId": "fcb1d0fe-7a60-4c72-bdbf-007e0acf3db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sparsity0.2\n",
            "Loss and Accuracy after pruning:\n",
            "79/79 [==============================] - 0s 3ms/step - loss: 0.7297 - accuracy: 0.7192\n",
            "[0.7296556234359741, 0.7192079424858093]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_sparsity(model):\n",
        "    total_weights = np.concatenate([x.numpy().flatten() for x in model.trainable_variables]  )\n",
        "    sparsity = 1 - np.count_nonzero(total_weights)/total_weights.size\n",
        "    return sparsity"
      ],
      "metadata": {
        "id": "l64hAiYxzkwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_sparsity(sparse_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgouD2GLzmIW",
        "outputId": "e1004e63-f85a-4d8c-d6bd-9a13114bc110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17632683625299994"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### save weights"
      ],
      "metadata": {
        "id": "ywX9mTM57Vqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# you need to save the model's weights, naming it 'my_model_weights.h5'\n",
        "sparse_model.save_weights(\"my_model_weights_3.h5\")\n",
        "\n",
        "# running this cell will immediately download a file called 'my_model_weights.h5'\n",
        "from google.colab import files\n",
        "files.download(\"my_model_weights_3.h5\")"
      ],
      "metadata": {
        "id": "TwZLcfuU7Yta",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "a3100b8d-515c-4c1d-961b-d1b839c8656a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_64c8b276-376c-4311-af38-379ecfc1912c\", \"my_model_weights_3.h5\", 2407560)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}